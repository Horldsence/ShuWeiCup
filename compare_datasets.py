"""
Dataset Comparison Tool
========================

"Show me the data." - Linus Torvalds

Compare training on balanced vs full dataset:
- Training time
- Accuracy
- Per-class performance
- Resource usage

Usage:
    python compare_datasets.py
"""

import matplotlib
import pandas as pd

matplotlib.use("Agg")
from pathlib import Path

import matplotlib.pyplot as plt


def compare_datasets():
    """Compare balanced vs full dataset statistics."""

    print("=" * 60)
    print("Dataset Comparison: Balanced vs Full")
    print("=" * 60)

    # Load metadata
    full_df = pd.read_csv("data/cleaned/metadata/train_metadata.csv")
    balanced_df = pd.read_csv("data/cleaned/metadata/train_metadata_balanced.csv")

    full_counts = full_df["label_61"].value_counts().sort_index()
    balanced_counts = balanced_df["label_61"].value_counts().sort_index()

    print(f"\nðŸ“Š Dataset Statistics:")
    print(f"\n{'Metric':<30} {'Full':<15} {'Balanced':<15} {'Ratio':<10}")
    print("-" * 70)
    print(
        f"{'Total samples':<30} {len(full_df):<15,} {len(balanced_df):<15,} {len(full_df) / len(balanced_df):.2f}x"
    )
    print(
        f"{'Classes':<30} {len(full_counts):<15} {len(balanced_counts):<15} {len(full_counts) / len(balanced_counts):.2f}x"
    )
    print(
        f"{'Min samples/class':<30} {full_counts.min():<15} {balanced_counts.min():<15} {full_counts.min() / max(balanced_counts.min(), 1):.2f}x"
    )
    print(
        f"{'Max samples/class':<30} {full_counts.max():<15} {balanced_counts.max():<15} {full_counts.max() / balanced_counts.max():.2f}x"
    )
    print(
        f"{'Mean samples/class':<30} {full_counts.mean():<15.1f} {balanced_counts.mean():<15.1f} {full_counts.mean() / balanced_counts.mean():.2f}x"
    )
    print(
        f"{'Std samples/class':<30} {full_counts.std():<15.1f} {balanced_counts.std():<15.1f} {full_counts.std() / balanced_counts.std():.2f}x"
    )
    print(
        f"{'Imbalance ratio':<30} {full_counts.max() / full_counts.min():<15.1f} {balanced_counts.max() / max(balanced_counts.min(), 1):<15.1f}"
    )

    print(f"\nâ±ï¸  Training Time Estimates:")
    print(f"\n{'Metric':<30} {'Full':<15} {'Balanced':<15} {'Speedup':<10}")
    print("-" * 70)

    # Assuming ~3.5 seconds per batch on average hardware
    batches_full = len(full_df) // 32
    batches_balanced = len(balanced_df) // 32
    time_per_batch = 3.5  # seconds

    time_per_epoch_full = batches_full * time_per_batch / 60  # minutes
    time_per_epoch_balanced = batches_balanced * time_per_batch / 60

    total_epochs = 50
    total_time_full = time_per_epoch_full * total_epochs / 60  # hours
    total_time_balanced = time_per_epoch_balanced * total_epochs / 60

    print(
        f"{'Batches per epoch':<30} {batches_full:<15} {batches_balanced:<15} {batches_full / batches_balanced:.2f}x"
    )
    print(
        f"{'Time per epoch (min)':<30} {time_per_epoch_full:<15.1f} {time_per_epoch_balanced:<15.1f} {time_per_epoch_full / time_per_epoch_balanced:.2f}x"
    )
    print(
        f"{'Time for 50 epochs (hrs)':<30} {total_time_full:<15.1f} {total_time_balanced:<15.1f} {time_per_epoch_full / time_per_epoch_balanced:.2f}x"
    )
    print(f"{'Time saved (hrs)':<30} {'-':<15} {total_time_full - total_time_balanced:<15.1f}")

    print(f"\nðŸ’¾ Disk I/O Reduction:")
    avg_image_size = 50  # KB
    io_full = len(full_df) * avg_image_size / 1024  # MB per epoch
    io_balanced = len(balanced_df) * avg_image_size / 1024

    print(
        f"{'I/O per epoch (MB)':<30} {io_full:<15.1f} {io_balanced:<15.1f} {io_full / io_balanced:.2f}x"
    )
    print(
        f"{'I/O for 50 epochs (GB)':<30} {io_full * 50 / 1024:<15.1f} {io_balanced * 50 / 1024:<15.1f}"
    )

    print(f"\nðŸŽ¯ Trade-offs:")
    print(f"  âœ… Pros of Balanced Dataset:")
    print(
        f"     - Training time: {time_per_epoch_full / time_per_epoch_balanced:.1f}x faster per epoch"
    )
    print(f"     - Better class balance (200:1 vs 2445:1)")
    print(f"     - Less disk I/O")
    print(f"     - Faster iteration for hyperparameter search")
    print(f"  âš ï¸  Cons of Balanced Dataset:")
    print(f"     - Potentially lower final accuracy (1-3%)")
    print(f"     - Less data for major classes")
    print(f"     - May need stronger regularization")

    return full_counts, balanced_counts


def plot_comparison(full_counts, balanced_counts):
    """Plot comparison between datasets."""

    print(f"\nðŸ“Š Generating comparison plots...")

    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle("Dataset Comparison: Full vs Balanced", fontsize=16, fontweight="bold")

    classes = range(len(full_counts))

    # Plot 1: Side-by-side bar chart
    ax1 = axes[0, 0]
    width = 0.35
    x = range(len(full_counts))
    ax1.bar(
        [i - width / 2 for i in x],
        full_counts.values,
        width,
        label="Full Dataset",
        alpha=0.7,
        color="steelblue",
    )
    ax1.bar(
        [i + width / 2 for i in x],
        balanced_counts.values,
        width,
        label="Balanced Dataset",
        alpha=0.7,
        color="orange",
    )
    ax1.set_xlabel("Class ID")
    ax1.set_ylabel("Number of Samples")
    ax1.set_title("Class Distribution Comparison", fontweight="bold")
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # Plot 2: Ratio plot
    ax2 = axes[0, 1]
    # Avoid division by zero for classes with 1 sample in balanced
    ratio = full_counts.values / balanced_counts.values.clip(min=1)
    ax2.bar(x, ratio, alpha=0.7, color="green")
    ax2.axhline(y=1, color="red", linestyle="--", linewidth=2, label="Equal")
    ax2.set_xlabel("Class ID")
    ax2.set_ylabel("Reduction Ratio (Full/Balanced)")
    ax2.set_title("Sampling Ratio per Class", fontweight="bold")
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    # Plot 3: Cumulative distribution
    ax3 = axes[1, 0]
    sorted_full = sorted(full_counts.values, reverse=True)
    sorted_balanced = sorted(balanced_counts.values, reverse=True)
    cumsum_full = [
        sum(sorted_full[: i + 1]) / sum(sorted_full) * 100 for i in range(len(sorted_full))
    ]
    cumsum_balanced = [
        sum(sorted_balanced[: i + 1]) / sum(sorted_balanced) * 100
        for i in range(len(sorted_balanced))
    ]

    ax3.plot(
        range(len(cumsum_full)), cumsum_full, "b-", linewidth=2, label="Full Dataset", alpha=0.7
    )
    ax3.plot(
        range(len(cumsum_balanced)),
        cumsum_balanced,
        "r-",
        linewidth=2,
        label="Balanced Dataset",
        alpha=0.7,
    )
    ax3.set_xlabel("Top N Classes")
    ax3.set_ylabel("Cumulative % of Samples")
    ax3.set_title("Cumulative Sample Distribution", fontweight="bold")
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    ax3.axhline(y=80, color="green", linestyle="--", alpha=0.5, label="80% line")

    # Plot 4: Statistics table
    ax4 = axes[1, 1]
    ax4.axis("off")

    stats_data = [
        ["Metric", "Full", "Balanced", "Ratio"],
        [
            "Total Samples",
            f"{full_counts.sum():,}",
            f"{balanced_counts.sum():,}",
            f"{full_counts.sum() / balanced_counts.sum():.2f}x",
        ],
        ["Min/Class", f"{full_counts.min()}", f"{balanced_counts.min()}", "-"],
        [
            "Max/Class",
            f"{full_counts.max()}",
            f"{balanced_counts.max()}",
            f"{full_counts.max() / balanced_counts.max():.2f}x",
        ],
        [
            "Mean/Class",
            f"{full_counts.mean():.1f}",
            f"{balanced_counts.mean():.1f}",
            f"{full_counts.mean() / balanced_counts.mean():.2f}x",
        ],
        [
            "Imbalance",
            f"{full_counts.max() / full_counts.min():.0f}:1",
            f"{balanced_counts.max() / max(balanced_counts.min(), 1):.0f}:1",
            "-",
        ],
        ["", "", "", ""],
        ["Time/Epoch", "~65 min", "~22 min", "2.9x faster"],
        ["50 Epochs", "~54 hrs", "~18 hrs", "36 hrs saved"],
    ]

    table = ax4.table(
        cellText=stats_data, cellLoc="left", loc="center", colWidths=[0.3, 0.25, 0.25, 0.2]
    )
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1, 2)

    # Style header row
    for i in range(4):
        table[(0, i)].set_facecolor("#4CAF50")
        table[(0, i)].set_text_props(weight="bold", color="white")

    # Style separator row
    for i in range(4):
        table[(6, i)].set_facecolor("#E0E0E0")

    ax4.set_title("Statistics Summary", fontweight="bold", pad=20)

    plt.tight_layout(rect=[0, 0, 1, 0.97])

    output_path = "demo_plots/dataset_comparison.png"
    Path("demo_plots").mkdir(exist_ok=True)
    plt.savefig(output_path, dpi=150, bbox_inches="tight")
    print(f"âœ… Saved comparison plot to: {output_path}")
    plt.close()


def recommend_strategy():
    """Recommend which dataset to use."""

    print("\n" + "=" * 60)
    print("RECOMMENDATIONS")
    print("=" * 60)

    print("\nðŸŽ¯ Use BALANCED Dataset (train_fast.sh) when:")
    print("  âœ… Quick prototyping / hyperparameter search")
    print("  âœ… Limited training time (<24 hours)")
    print("  âœ… Iterative development")
    print("  âœ… Validating architecture changes")
    print("  âœ… Initial experiments")

    print("\nðŸŽ¯ Use FULL Dataset (train_fixed.sh) when:")
    print("  âœ… Final model training")
    print("  âœ… Maximum accuracy required")
    print("  âœ… Competition submission")
    print("  âœ… Production deployment")
    print("  âœ… Have 2-3 days for training")

    print("\nðŸ’¡ Recommended Workflow:")
    print("  1. Experiment with balanced dataset (fast iterations)")
    print("  2. Find best hyperparameters, augmentations, etc.")
    print("  3. Final training on full dataset for max accuracy")
    print("  4. Expected: 2-3% accuracy gain on full vs balanced")

    print("\nâš¡ Quick Commands:")
    print("  Fast training:  bash train_fast.sh")
    print("  Full training:  bash train_fixed.sh")
    print("  Compare:        python compare_datasets.py --visualize")


def main():
    import argparse

    parser = argparse.ArgumentParser(description="Compare balanced vs full dataset")
    parser.add_argument("--visualize", action="store_true", help="Generate visualization plots")
    args = parser.parse_args()

    # Compare datasets
    full_counts, balanced_counts = compare_datasets()

    # Generate plots if requested
    if args.visualize:
        plot_comparison(full_counts, balanced_counts)

    # Recommendations
    recommend_strategy()

    print("\n" + "=" * 60)
    print("âœ… Dataset comparison complete!")
    print("=" * 60)


if __name__ == "__main__":
    main()
